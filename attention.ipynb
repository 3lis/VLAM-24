{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["qF-J5lufn6Iu","rJBboMbouefN","OFz6U3jMuYKy","Y0P65fKtxwr6","956LK385maN3","jBox2pO4mlzp","E0JEK6lhyMuw","XHw3i3AYF55s","QaIHcgvOH8OV"],"toc_visible":true,"authorship_tag":"ABX9TyNiYNhuHFDtQ5U8KKoRjgtF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3jV_3puX-v9E","executionInfo":{"status":"ok","timestamp":1709189973882,"user_tz":-60,"elapsed":3694,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"outputs":[],"source":["import  os\n","import  numpy               as np\n","import  tensorflow          as tf\n","from    tensorflow          import keras"]},{"cell_type":"markdown","source":["# Embedding"],"metadata":{"id":"qF-J5lufn6Iu"}},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"rJBboMbouefN"}},{"cell_type":"code","source":["# https://nlp.stanford.edu/projects/glove/\n","glove_file  = \"glove.6B.50d.txt\"\n","\n","!wget -O {glove_file} https://www.dropbox.com/scl/fi/y328s9lbz8c9glp7al02p/glove.6B.50d.txt?rlkey=m81pwe06f8tpb947fl3y78nlo&dl=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_FPiaCbn51G","executionInfo":{"status":"ok","timestamp":1709189978519,"user_tz":-60,"elapsed":4641,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"26c6b8fb-50bd-411f-b623-00edb623c15a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-29 06:59:33--  https://www.dropbox.com/scl/fi/y328s9lbz8c9glp7al02p/glove.6B.50d.txt?rlkey=m81pwe06f8tpb947fl3y78nlo\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com/cd/0/inline/COKsc3v9WDFSUUZcy6rqfHmAthbVdqWn2SAlCIu2TeXbNnJO4hZw-Jqdx8A9uveI3UV4sNOa-n9W_IXtoCQeznWsS17LmNSw2Ias_tEsh3EUl_ohWi9Z81inxSnVgSdwDwQ/file# [following]\n","--2024-02-29 06:59:34--  https://uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com/cd/0/inline/COKsc3v9WDFSUUZcy6rqfHmAthbVdqWn2SAlCIu2TeXbNnJO4hZw-Jqdx8A9uveI3UV4sNOa-n9W_IXtoCQeznWsS17LmNSw2Ias_tEsh3EUl_ohWi9Z81inxSnVgSdwDwQ/file\n","Resolving uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com (uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6019:15::a27d:40f\n","Connecting to uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com (uc9f475ff404db2f988fd30ff52c.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 171350079 (163M) [text/plain]\n","Saving to: ‘glove.6B.50d.txt’\n","\n","glove.6B.50d.txt    100%[===================>] 163.41M  57.1MB/s    in 2.9s    \n","\n","2024-02-29 06:59:38 (57.1 MB/s) - ‘glove.6B.50d.txt’ saved [171350079/171350079]\n","\n"]}]},{"cell_type":"code","source":["# read the embedding file\n","# return a dict with words (strings) as keys and embedding vectors (np.array) as value\n","def read_glove( glove_file ):\n","    embedding   = {}\n","    with open( glove_file, 'r' ) as f:\n","        cnt = 0\n","        for l in f:\n","            word, vector        = l.split( maxsplit=1 )\n","            vector              = np.matrix( vector ).A1  # convert to normal np.array\n","            embedding[ word ]   = vector\n","\n","            cnt += 1\n","            if not cnt % 10000:\n","                print( f\"read {cnt:,} of 400,000 words\" )\n","\n","    print( \"Done!\")\n","    return embedding"],"metadata":{"id":"Y2D7BPkvpPOp","executionInfo":{"status":"ok","timestamp":1709189978520,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# takes about 2m 30s with the short file\n","# (the long file takes about 15m)\n","embedding   = read_glove( glove_file )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMgMol9CpRW6","executionInfo":{"status":"ok","timestamp":1709190099962,"user_tz":-60,"elapsed":121444,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"524410e5-930b-4663-f468-1ddcbc5eb0f1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["read 10,000 of 400,000 words\n","read 20,000 of 400,000 words\n","read 30,000 of 400,000 words\n","read 40,000 of 400,000 words\n","read 50,000 of 400,000 words\n","read 60,000 of 400,000 words\n","read 70,000 of 400,000 words\n","read 80,000 of 400,000 words\n","read 90,000 of 400,000 words\n","read 100,000 of 400,000 words\n","read 110,000 of 400,000 words\n","read 120,000 of 400,000 words\n","read 130,000 of 400,000 words\n","read 140,000 of 400,000 words\n","read 150,000 of 400,000 words\n","read 160,000 of 400,000 words\n","read 170,000 of 400,000 words\n","read 180,000 of 400,000 words\n","read 190,000 of 400,000 words\n","read 200,000 of 400,000 words\n","read 210,000 of 400,000 words\n","read 220,000 of 400,000 words\n","read 230,000 of 400,000 words\n","read 240,000 of 400,000 words\n","read 250,000 of 400,000 words\n","read 260,000 of 400,000 words\n","read 270,000 of 400,000 words\n","read 280,000 of 400,000 words\n","read 290,000 of 400,000 words\n","read 300,000 of 400,000 words\n","read 310,000 of 400,000 words\n","read 320,000 of 400,000 words\n","read 330,000 of 400,000 words\n","read 340,000 of 400,000 words\n","read 350,000 of 400,000 words\n","read 360,000 of 400,000 words\n","read 370,000 of 400,000 words\n","read 380,000 of 400,000 words\n","read 390,000 of 400,000 words\n","read 400,000 of 400,000 words\n","Done!\n"]}]},{"cell_type":"code","source":["# functions to play with embeddings\n","\n","# check if word exists and return its embedding vector\n","def embed( word ):\n","    if isinstance( word, str ):\n","        if word not in embedding.keys():\n","            return False\n","        return embedding[ word ]\n","    return word\n","\n","\n","# compute similarity between two words [-1, 1]\n","# -1 = max similarity, 1 = no similarity\n","def sim( word1, word2 ):\n","    word1   = embed( word1 )\n","    word2   = embed( word2 )\n","    s       = keras.losses.cosine_similarity( word1, word2 )\n","    return s.numpy()\n","\n","\n","def plus( word1, word2 ):\n","    word1   = embed( word1 )\n","    word2   = embed( word2 )\n","    return word1 + word2\n","\n","\n","def minus( word1, word2 ):\n","    word1   = embed( word1 )\n","    word2   = embed( word2 )\n","    return word1 - word2\n","\n","\n","# get the \"closest\" words to a given word\n","def closest( word, n_words=5, limit=50000 ):\n","    word      = embed( word )\n","    cnt       = 0\n","    best      = [ ( None, 1.0 ) ]    # list of ( word, score )\n","    for w in embedding.keys():\n","        score       = sim( embedding[ w ], word )\n","        if ( score + 1 ) < 0.05:\n","            continue\n","\n","        for i, ( v, s ) in enumerate( best ):\n","            if score < s:\n","                best.insert( i, ( w, score ) )\n","                del best[ n_words: ]\n","                break\n","\n","        cnt += 1\n","        if not cnt % 1000:\n","            print( f\"checked {cnt:,} of {limit:,} words\" )\n","        if cnt > limit:\n","            print()\n","            break\n","\n","    return best"],"metadata":{"id":"EpFX__8cpegA","executionInfo":{"status":"ok","timestamp":1709190099963,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"OFz6U3jMuYKy"}},{"cell_type":"code","source":["embed( 'unicorn' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Es-YgfxEpiGQ","executionInfo":{"status":"ok","timestamp":1709190099963,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"1c2a3654-c65b-4ad8-db02-cff1c04bde48"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.9628   , -0.7262   , -1.0204   , -0.12449  ,  0.5857   ,\n","        0.24912  ,  0.1899   , -0.53152  ,  0.27576  , -0.2448   ,\n","        0.56746  ,  0.56175  , -0.066513 ,  0.42018  , -0.14651  ,\n","       -0.30215  , -0.045488 ,  0.79528  , -1.1222   ,  0.068902 ,\n","       -0.08587  , -0.16382  , -0.3923   ,  0.13409  , -0.43265  ,\n","        0.0018246, -1.2473   ,  0.32282  ,  0.074383 , -0.70834  ,\n","       -0.06777  ,  0.10383  , -0.35492  ,  0.66333  , -0.22843  ,\n","        0.57841  ,  0.0057448, -1.2199   , -0.31636  , -0.47167  ,\n","        0.38949  , -0.26445  , -0.32037  , -0.70928  ,  0.39919  ,\n","       -0.14546  ,  0.67401  , -0.67832  , -0.016107 , -0.54813  ])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["sim( 'dog', 'wolf' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uD3IY480pij-","executionInfo":{"status":"ok","timestamp":1709190101873,"user_tz":-60,"elapsed":1913,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"48a487be-c964-473d-d9a9-fc5b017ee740"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.6943803101202853"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["sim( 'dog', 'galaxy' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pW2sVddqplR5","executionInfo":{"status":"ok","timestamp":1709190102092,"user_tz":-60,"elapsed":221,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"8f54e909-d163-40a7-d469-fe6c43969574"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.13304946376525956"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["closest( 'queen', n_words=10, limit=20000 )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvAeqBUXpnXe","executionInfo":{"status":"ok","timestamp":1709190130489,"user_tz":-60,"elapsed":28398,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"a6437d9b-f310-45a1-9bff-7c3ab9266201"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["checked 1,000 of 20,000 words\n","checked 2,000 of 20,000 words\n","checked 3,000 of 20,000 words\n","checked 4,000 of 20,000 words\n","checked 5,000 of 20,000 words\n","checked 6,000 of 20,000 words\n","checked 7,000 of 20,000 words\n","checked 8,000 of 20,000 words\n","checked 9,000 of 20,000 words\n","checked 10,000 of 20,000 words\n","checked 11,000 of 20,000 words\n","checked 12,000 of 20,000 words\n","checked 13,000 of 20,000 words\n","checked 14,000 of 20,000 words\n","checked 15,000 of 20,000 words\n","checked 16,000 of 20,000 words\n","checked 17,000 of 20,000 words\n","checked 18,000 of 20,000 words\n","checked 19,000 of 20,000 words\n","checked 20,000 of 20,000 words\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('princess', -0.851516638750669),\n"," ('lady', -0.8050609250765663),\n"," ('elizabeth', -0.7873042176943493),\n"," ('king', -0.7839043010964117),\n"," ('prince', -0.7821860976090151),\n"," ('coronation', -0.7692777928548158),\n"," ('consort', -0.7626097498967264),\n"," ('royal', -0.744286480167597),\n"," ('crown', -0.7382649680186562),\n"," ('victoria', -0.7285771630710364)]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["w = minus( 'king', 'man' )\n","w = plus( w, 'woman' )\n","sim( w, 'queen' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"on_cACUTppkp","executionInfo":{"status":"ok","timestamp":1709190210848,"user_tz":-60,"elapsed":191,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"bdefebc7-7e89-4d52-a40f-118f3574da6c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.8609581258578944"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# Attention"],"metadata":{"id":"Y0P65fKtxwr6"}},{"cell_type":"markdown","source":["### Classes"],"metadata":{"id":"956LK385maN3"}},{"cell_type":"code","source":["class Attention( keras.layers.Layer ):\n","    \"\"\"\n","    this class implements a dot-product attention layer:\n","        A( Q, K, V ) = softmax( ( Q K^T ) / sqrt( dim ) ) V\n","    \"\"\"\n","\n","    def __init__( self, dim, **kwargs ):\n","        \"\"\"\n","        initialization of the class\n","        inputs:\n","            dim         [int] internal dimension (and input vector size / embedding)\n","        \"\"\"\n","        super().__init__( **kwargs )\n","        self.dim        = dim\n","\n","\n","    def call( self, q, k, v ):\n","        \"\"\"\n","        compute the scaled dot-product attention\n","        inputs:\n","            q           [tensor] query\n","            k           [tensor] key\n","            v           [tensor] value\n","        \"\"\"\n","        scores          = tf.matmul( q, k, transpose_b=True )\n","        norm            = tf.math.sqrt( tf.cast( self.dim, tf.float32 ) ) # to normalize\n","        scores          /= norm\n","        softm           = tf.nn.softmax( scores )\n","        att             = tf.matmul( softm, v )\n","        return att, softm   # output, weigth matrix\n"],"metadata":{"id":"r9rhb6c1AGfJ","executionInfo":{"status":"ok","timestamp":1709190172526,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention( keras.layers.Layer ):\n","    \"\"\"\n","    this class implements a multi-head attention layer\n","    \"\"\"\n","\n","    def __init__( self, dim, n_heads, **kwargs ):\n","        \"\"\"\n","        initialization of the class, with all the linear algebra ingredients for query, key, value, output\n","        inputs:\n","            dim         [int] dimension\n","            n_heads     [int] number of heads\n","        \"\"\"\n","        super().__init__( **kwargs )\n","        self.dim        = dim\n","        self.n_heads    = n_heads\n","        self.attention  = Attention( self.dim )\n","        self.Q          = keras.layers.Dense( self.dim )    # without activation function, just a matrix\n","        self.K          = keras.layers.Dense( self.dim )    # just a matrix\n","        self.V          = keras.layers.Dense( self.dim )    # just a matrix\n","        self.O          = keras.layers.Dense( self.dim )    # just a matrix\n","\n","\n","    def _split_heads( self, x ):    # la seq_length non viene mai passata da nessuno! se la ricava da solo tramite tensori\n","        \"\"\"\n","        split a tensor into heads just by adding a dimension and rearranging the shape\n","        NOTE the special use of -1 in tf.reshape that compute automatically the size of a dimension\n","        NOTE that it does not work using x.shape for retrieving the original shape, tf.shape() should be used\n","        \"\"\"\n","        original_shape  = tf.shape( x )                                                     # batch X seq_length X dim\n","        headed_shape    = ( original_shape[ 0 ], original_shape[ 1 ], self.n_heads, -1 )    # batch X seq_length X n_head X new_dim\n","        x               = tf.reshape( x, shape=headed_shape )\n","        x               = tf.transpose( x, perm=( 0, 2, 1, 3 ) )                            # batch X n_head X seq_length X new_dim\n","        return x\n","\n","\n","    def _join_heads( self, x ):\n","        \"\"\"\n","        rejoin a tensor collapsing its heads\n","        essentialy reverts the operations of _split_heads()\n","        NOTE see _split_heads()\n","        \"\"\"\n","        x               = tf.transpose( x, perm=(0, 2, 1, 3) )\n","        headed_shape    = tf.shape( x )\n","        original_shape  = ( headed_shape[ 0 ], headed_shape[ 1 ], self.dim )\n","        x               = tf.reshape( x, shape=original_shape )\n","        return x\n","\n","\n","    def call( self, q, k, v, return_matrix=False ):\n","        \"\"\"\n","        compute the multi-head attention\n","        inputs:\n","            q               [tensor] query\n","            k               [tensor] key\n","            v               [tensor] value\n","            return_matrix   [bool]  if True return also the attention matrix\n","        \"\"\"\n","        q               = self.Q( q )\n","        k               = self.K( k )\n","        v               = self.V( v )\n","\n","        q               = self._split_heads( q )\n","        k               = self._split_heads( k )\n","        v               = self._split_heads( v )\n","\n","        a, matrix       = self.attention( q, k, v )\n","        a               = self._join_heads( a )\n","        o               = self.O( a )\n","        if return_matrix:\n","            return o, matrix\n","        return o\n"],"metadata":{"id":"Qt-5VxfDCWc-","executionInfo":{"status":"ok","timestamp":1709190172526,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"jBox2pO4mlzp"}},{"cell_type":"code","source":["mha     = MultiHeadAttention( 4, 2 )\n","x       = 0.1 * np.random.random( ( 1, 5, 4 ) )\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6ascJvyuCsH","executionInfo":{"status":"ok","timestamp":1709190172527,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"5d0cd76e-8881-4f6a-e4cf-c997887375ce"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.03903032, 0.01083386, 0.02229455, 0.06199888],\n","        [0.05615571, 0.00544831, 0.00417441, 0.00984983],\n","        [0.01555901, 0.06852272, 0.00036552, 0.05989993],\n","        [0.0623731 , 0.02540096, 0.06532834, 0.08206647],\n","        [0.052377  , 0.0748466 , 0.02227033, 0.04393784]]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["o, m    = mha( x, x, x, return_matrix=True )\n","m       # batch X n_head X seq_length X seq_length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Upz97IFuhT-","executionInfo":{"status":"ok","timestamp":1709190172855,"user_tz":-60,"elapsed":333,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"316509e8-5a7e-4290-da5f-62a216c1a932"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 5, 5), dtype=float32, numpy=\n","array([[[[0.20000912, 0.20003867, 0.20000707, 0.19995843, 0.19998673],\n","         [0.20003115, 0.20000991, 0.1999941 , 0.20000437, 0.19996051],\n","         [0.20001464, 0.2001047 , 0.2000218 , 0.19988224, 0.19997664],\n","         [0.20008124, 0.20000291, 0.19997898, 0.20003876, 0.19989805],\n","         [0.20008594, 0.20005971, 0.19999167, 0.19997318, 0.19988948]],\n","\n","        [[0.200186  , 0.1998892 , 0.19997014, 0.20018448, 0.19977021],\n","         [0.20003492, 0.19999199, 0.20007287, 0.19993548, 0.19996472],\n","         [0.2002897 , 0.19981346, 0.19986844, 0.20039484, 0.19963354],\n","         [0.2002908 , 0.19983216, 0.19998638, 0.2002465 , 0.19964418],\n","         [0.20027527, 0.19983636, 0.1999581 , 0.20027001, 0.19966021]]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["x[ 0 ][ 0 ] = 8.4 * np.ones( ( 4, ) )\n","x[ 0 ][ 3 ] = 7.8 * np.ones( ( 4, ) )\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TMz6k45uh58","executionInfo":{"status":"ok","timestamp":1709190172856,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"57251237-5999-49da-959d-fafbd038990d"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[8.40000000e+00, 8.40000000e+00, 8.40000000e+00, 8.40000000e+00],\n","        [5.61557130e-02, 5.44831296e-03, 4.17441441e-03, 9.84982796e-03],\n","        [1.55590064e-02, 6.85227169e-02, 3.65516845e-04, 5.98999318e-02],\n","        [7.80000000e+00, 7.80000000e+00, 7.80000000e+00, 7.80000000e+00],\n","        [5.23770017e-02, 7.48466040e-02, 2.22703255e-02, 4.39378449e-02]]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["o, m    = mha( x, x, x, return_matrix=True )\n","m"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKKfe1JUvwz4","executionInfo":{"status":"ok","timestamp":1709190172856,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"9d807b98-e1bb-41be-982d-ec5ae5f6ef74"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 5, 5), dtype=float32, numpy=\n","array([[[[2.5880080e-08, 3.4884879e-01, 3.3941177e-01, 8.3795584e-08,\n","          3.1173933e-01],\n","         [1.9494672e-01, 2.0319791e-01, 2.0318189e-01, 1.9552571e-01,\n","          2.0314774e-01],\n","         [1.7985354e-01, 2.1278106e-01, 2.1269292e-01, 1.8202762e-01,\n","          2.1264489e-01],\n","         [8.3339138e-08, 3.4774289e-01, 3.3899918e-01, 2.4811752e-07,\n","          3.1325760e-01],\n","         [1.8050894e-01, 2.1237469e-01, 2.1230248e-01, 1.8261985e-01,\n","          2.1219397e-01]],\n","\n","        [[4.5973822e-11, 3.3471370e-01, 3.7386197e-01, 2.3580152e-10,\n","          2.9142430e-01],\n","         [1.8830389e-01, 2.0734446e-01, 2.0742832e-01, 1.8960713e-01,\n","          2.0731619e-01],\n","         [1.9555975e-01, 2.0282724e-01, 2.0288306e-01, 1.9608536e-01,\n","          2.0264462e-01],\n","         [2.3279323e-10, 3.3472875e-01, 3.7093645e-01, 1.0624041e-09,\n","          2.9433474e-01],\n","         [1.8540958e-01, 2.0920554e-01, 2.0933300e-01, 1.8703076e-01,\n","          2.0902115e-01]]]], dtype=float32)>"]},"metadata":{},"execution_count":17}]}]}