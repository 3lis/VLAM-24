{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmWuU3Zu2C-_"
      },
      "outputs": [],
      "source": [
        "import  os\n",
        "import  numpy                   as np\n",
        "import  pandas                  as pd\n",
        "from    PIL                     import Image, ImageDraw\n",
        "from    IPython.display         import Image    as IPythonImage\n",
        "\n",
        "import  tensorflow              as tf\n",
        "from    tensorflow              import keras\n",
        "from    tensorflow.keras        import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pendulum"
      ],
      "metadata": {
        "id": "PB1o0PY4-JDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "EwPgjUJJEHNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS        = 2                     # number of training epochs\n",
        "LRATE           = 0.001                 # learning rate\n",
        "DROPOUT         = 0.2                   # dropout probability during training of attention\n",
        "NUM_HEADS       = 4                     # number of attention heads\n",
        "SEQ_LEN         = 40                    # length of input sequence\n",
        "BATCH_SIZE      = 16                    # batch size of the generator\n",
        "STRIDE          = 1                     # stride for sampling sequence in the generator\n",
        "DATA_DIM        = 6                     # dimension of a data sample (2D coordinates for 3 points)\n",
        "EMBED_DIM       = 64                    # embedding dimension\n",
        "EMBED_MODE      = 'time2vec'            # embedding modality - current options are:\n",
        "                                            # None        no embedding at all\n",
        "                                            # 'conv1d'    use 1D convolution\n",
        "                                            # 'time2vec'  use Time2Vec\n",
        "\n",
        "GIF_FILE        = \"output.gif\"          # output file\n",
        "IMG_SIZE        = ( 256, 256 )          # image size\n",
        "IMG_EDGE        = 0.15                  # minimum border as fraction of 1.0\n",
        "COL_BACK        = 20                    # background gray level\n",
        "COL_TRUE        = \"#00ff00\"             # color of ground truth\n",
        "COL_PRED        = \"#ff0000\"             # color of prediction\n",
        "COL_RODS        = \"#ffffff\"             # color of constraints\n",
        "\n"
      ],
      "metadata": {
        "id": "UoiY1j8kEK08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "KF9eDPWp-LEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data download"
      ],
      "metadata": {
        "id": "kMOKl4hZzkoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_t2v      = \"pend_t2v_e2000.h5\"               # pre-trained model to load\n",
        "inp_zip     = \"pend.zip\"                        # archive with .dta files\n",
        "inp_path    = \"GeneralisedPendulum\"             # path and prefix of the input data files\n",
        "header      = 3                                 # num of lines to skip in .dta files\n",
        "\n",
        "# there are 10 .dta files, from 8 to 18\n",
        "# data splitting into train and test\n",
        "train_test  = {\n",
        "    'train' : [ 8, 10, 11, 13, 15, 16, 18 ],\n",
        "    'test'  : [ 9, 14, 17 ]\n",
        "}"
      ],
      "metadata": {
        "id": "Kjev97TL-6UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O {nn_t2v} https://www.dropbox.com/scl/fi/fgsfklo5z944acm6l0nu3/pend_t2v_e2000.h5?rlkey=ej6uqo6tpggmtn204r88vg6fu&dl=0\n",
        "!wget -O {inp_zip} https://www.dropbox.com/scl/fi/ell5z8bje172n0c6st0e3/pend.zip?rlkey=t5mxsl2cev6xbugogcd3ej028&dl=0"
      ],
      "metadata": {
        "id": "HYcb5Jnk_2cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir {inp_path}\n",
        "!unzip {inp_zip} -d {inp_path}"
      ],
      "metadata": {
        "id": "GIcxxZlT_7JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data reading"
      ],
      "metadata": {
        "id": "_TIJnemDznTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file_pend( n, points_only ):\n",
        "    \"\"\"\n",
        "    Read a .dta file of given index.\n",
        "    Return an array with the points' coordinates in time.\n",
        "\n",
        "    params:\n",
        "        n           [int] index of the .dta file (from 8 to 18)\n",
        "        points_only [bool] whether to return only P1, P2, P3 or also A1, A2, B1, B2\n",
        "\n",
        "    return:\n",
        "        [np.array]\n",
        "    \"\"\"\n",
        "\n",
        "    f   = f\"{inp_path}/{inp_path}{n:02d}.dta\"\n",
        "    assert os.path.isfile( f ), f\".dta file {f} not found\"\n",
        "    r   = pd.read_csv( f, sep='\\t', header=header )\n",
        "\n",
        "    if points_only:\n",
        "        points      = np.array( [\n",
        "                r[ 'x1' ],  r[ 'y1' ],\n",
        "                r[ 'x2' ],  r[ 'y2' ],\n",
        "                r[ 'x3' ],  r[ 'y3' ]\n",
        "        ] ).T\n",
        "\n",
        "    else:\n",
        "        points      = np.array( [\n",
        "                r[ 'x1' ],  r[ 'y1' ],\n",
        "                r[ 'x2' ],  r[ 'y2' ],\n",
        "                r[ 'x3' ],  r[ 'y3' ],\n",
        "                r[ 'A1x' ], r[ 'A1y' ],\n",
        "                r[ 'B1x' ], r[ 'B1y' ],\n",
        "                r[ 'A2x' ], r[ 'A2y' ],\n",
        "                r[ 'B2x' ], r[ 'B2y' ]\n",
        "        ] ).T\n",
        "\n",
        "    return points"
      ],
      "metadata": {
        "id": "l7tS8jlf-S08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_sequences( seq_len=20, stride=1, batch_size=32, train=True ):\n",
        "    \"\"\"\n",
        "    Build a data Generator that produce data samples from the .dta files.\n",
        "    Samples are couples of an input and a target. An input is a sequence of seq_len elements,\n",
        "    and a target is the single following element.\n",
        "\n",
        "    params:\n",
        "        files       [list] indices of .dta files to use\n",
        "        seq_len     [int] input sequence length\n",
        "        stride      [int] downsamplig factor when selecting samples\n",
        "                    (when =1 all possible sequences will be generated, half the sequence when =2, and so on)\n",
        "        batch_size  [int]\n",
        "        train       [bool] whether to read from training or test data\n",
        "\n",
        "    return:\n",
        "        [tf.data.Dataset] that yields a tuple containing a batch of inputs and a batch of targets\n",
        "    \"\"\"\n",
        "    tr_ts   = 'train' if train else 'test'\n",
        "    files   = train_test[ tr_ts ]\n",
        "    dset    = None\n",
        "\n",
        "    for n in files:\n",
        "        p       = read_file_pend( n, points_only=True )\n",
        "        # start reading inputs from beginning, finish reading before last 'seq_len' elements\n",
        "        inp     = p[ : -seq_len ]\n",
        "        # start reading outputs after first 'seq_len' elements, finish reading at the end\n",
        "        targ    = p[ seq_len: ]\n",
        "\n",
        "        d       = utils.timeseries_dataset_from_array(\n",
        "                inp,\n",
        "                targ,\n",
        "                sequence_length = seq_len,\n",
        "                sequence_stride = stride,\n",
        "                batch_size      = batch_size,\n",
        "                shuffle         = train\n",
        "        )\n",
        "        dset    = d if dset is None else dset.concatenate( d )\n",
        "\n",
        "    return dset"
      ],
      "metadata": {
        "id": "-0K4vMaQAt-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dset():\n",
        "    \"\"\"\n",
        "    Create the training and test sets\n",
        "\n",
        "    return:\n",
        "        [tuple] of [tf.data.Dataset] training and test sets\n",
        "    \"\"\"\n",
        "    print( \"Now creating the datasets...\\n\" )\n",
        "    train_set  = gen_sequences( seq_len=SEQ_LEN, stride=STRIDE, batch_size=BATCH_SIZE, train=True )\n",
        "    test_set   = gen_sequences( seq_len=SEQ_LEN, stride=STRIDE, batch_size=BATCH_SIZE, train=False )\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "p6dqUwalk0m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time2Vec\n",
        "\n",
        "$e_{0}\\left(v\\right)=\\mathbf{w}_1v+b_1$\n",
        "\n",
        "$e_{i>0}\\left(v\\right)=\\sin\\left(\\mathbf{w}_2v+\\mathbf{b}_2\\right)$"
      ],
      "metadata": {
        "id": "b2Mq_aVXD2B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2Vec( keras.layers.Layer ):\n",
        "    \"\"\"\n",
        "    Class implementation of a Time2Vec embedding layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__( self, **kwargs ):\n",
        "        \"\"\"\n",
        "        Initialization of the class\n",
        "        \"\"\"\n",
        "        super().__init__( **kwargs )\n",
        "        self.inp_dim    = DATA_DIM      # input dimension (3 points with 2D space)\n",
        "        self.emb_dim    = EMBED_DIM     # embedding dimension\n",
        "\n",
        "\n",
        "    def build( self, input_shape ):\n",
        "        \"\"\"\n",
        "        Default method for class keras.layers.Layer definying all traininable weights\n",
        "        \"\"\"\n",
        "        self.wa         = self.add_weight(\n",
        "            shape           = ( self.inp_dim, self.emb_dim - 1 ),\n",
        "            initializer     = 'uniform',\n",
        "            name            = \"WeightT2VLinearMatrix\",\n",
        "            trainable       = True\n",
        "        )\n",
        "        self.ba         = self.add_weight(\n",
        "            shape=( 1, self.emb_dim - 1 ),\n",
        "            initializer     = 'uniform',\n",
        "            name            = \"WeightT2VLinearOffset\",\n",
        "            trainable       = True\n",
        "        )\n",
        "        self.wb         = self.add_weight(\n",
        "            shape=( self.inp_dim, 1 ),\n",
        "            initializer     = 'uniform',\n",
        "            name            = \"WeightT2VPeriodicMatrix\",\n",
        "            trainable       = True\n",
        "        )\n",
        "        self.bb         = self.add_weight(\n",
        "            shape=( 1, 1 ),\n",
        "            initializer     = 'uniform',\n",
        "            name            = \"WeightT2VPeriodicOffset\",\n",
        "            trainable       = True\n",
        "        )\n",
        "\n",
        "\n",
        "    def call( self, inputs ):\n",
        "        \"\"\"\n",
        "        Default method for class keras.layers.Layer specifying what the layer does when applied to the input.\n",
        "        Implement the Time2Vec formula.\n",
        "        \"\"\"\n",
        "        # NOTE multiplication with tf.tensordot() is necessary to obtain the final embedding size\n",
        "        linear          = tf.tensordot( inputs, self.wb, axes=( (-1), (0) ) )\n",
        "        linear          += self.bb\n",
        "        periodic        = tf.tensordot( inputs, self.wa, axes=( (-1), (0) ) )\n",
        "        periodic        += self.ba\n",
        "        periodic        = tf.math.sin( periodic )\n",
        "        t2v             = tf.concat( [ linear, periodic ], -1 )\n",
        "        return t2v"
      ],
      "metadata": {
        "id": "eN1LV2esD1KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer decoder"
      ],
      "metadata": {
        "id": "n86iUt9-FA8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransDecoder( object ):\n",
        "    \"\"\"\n",
        "    Essential Transformer decoder with custom embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__( self ):\n",
        "        \"\"\"\n",
        "        Initialization of the class\n",
        "        \"\"\"\n",
        "        self.num_heads      = NUM_HEADS\n",
        "        self.length         = SEQ_LEN                               # length of sequence of inputs\n",
        "        self.inp_dim        = DATA_DIM                              # input dimension (3 points with 2D space)\n",
        "        self.dropout        = DROPOUT if TRAIN else 0.0\n",
        "        self.loss_func      = keras.losses.MeanSquaredError()\n",
        "\n",
        "        if EMBED_MODE is None:\n",
        "            # no embedding\n",
        "            self.dim        = self.inp_dim\n",
        "            self.embedding  = lambda x: x\n",
        "        elif EMBED_MODE == \"conv1d\":\n",
        "            # used conv1D to apply the same matrix to all vectors in the sequence\n",
        "            self.dim        = EMBED_DIM\n",
        "            self.embedding  = keras.layers.Conv1D( self.dim, kernel_size=1, name=\"Conv1DEmbed\" )\n",
        "        elif EMBED_MODE == \"time2vec\":\n",
        "            # use Time2Vec\n",
        "            self.dim        = EMBED_DIM\n",
        "            self.embedding  = Time2Vec( name=\"Time2VecEmbed\" )\n",
        "\n",
        "        self.attention      = self._attention()\n",
        "        self.model          = self.create_model()\n",
        "\n",
        "\n",
        "    def _attention( self ):\n",
        "        \"\"\"\n",
        "        Multi-head attention layer\n",
        "        \"\"\"\n",
        "        att         = keras.layers.MultiHeadAttention(\n",
        "                num_heads   = self.num_heads,\n",
        "                key_dim     = self.dim // self.num_heads,\n",
        "                dropout     = self.dropout,\n",
        "                name        = \"MHAttention\"\n",
        "        )\n",
        "        return att\n",
        "\n",
        "\n",
        "    def create_model( self ):\n",
        "        \"\"\"\n",
        "        Create the model\n",
        "        \"\"\"\n",
        "        inputs      = keras.layers.Input( shape=( self.length, self.inp_dim ), dtype=tf.float32 )\n",
        "        x           = self.embedding( inputs )\n",
        "        x           = self.attention( x, x, x )\n",
        "        x           = keras.layers.LayerNormalization( name=\"NormLayer\" )( x )\n",
        "        x           = keras.layers.Dense( self.inp_dim, activation='sigmoid', name=\"Dense1\" )( x )\n",
        "        # x now has shape [ batch, seq_len, inp_dim ]\n",
        "        x           = keras.layers.Flatten( name=\"FlattenDense\" )( x )\n",
        "        outputs     = keras.layers.Dense( self.inp_dim, name=\"Dense2\" )( x )\n",
        "\n",
        "        model       = keras.Model( inputs=inputs, outputs=outputs )\n",
        "        return model"
      ],
      "metadata": {
        "id": "6OadJMHqFDBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model( nn, train_set, test_set ):\n",
        "    \"\"\"\n",
        "    Train a model and save the weigths\n",
        "\n",
        "    params:\n",
        "        nn          [keras.Model]\n",
        "        train_set   [tf.data.Dataset]\n",
        "        test_set    [tf.data.Dataset]\n",
        "\n",
        "    return:\n",
        "        [keras.Model] trained model\n",
        "        [keras.History.history] trainin log\n",
        "    \"\"\"\n",
        "    nn.model.compile(\n",
        "            optimizer   = keras.optimizers.Adam( learning_rate=LRATE ),\n",
        "            loss        = nn.loss_func,\n",
        "            metrics     = [ 'accuracy' ]\n",
        "    )\n",
        "\n",
        "    hist        = nn.model.fit(\n",
        "            x                   = train_set,\n",
        "            validation_data     = test_set,\n",
        "            epochs              = N_EPOCHS,\n",
        "            verbose             = 1\n",
        "    )\n",
        "\n",
        "    nn.model.save_weights( nn_final )\n",
        "    return nn, hist"
      ],
      "metadata": {
        "id": "dhm6XKUIFW7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image output generation"
      ],
      "metadata": {
        "id": "gE4UvD_cGsfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scaling( points ):\n",
        "    \"\"\"\n",
        "    Compute the scaling factors for a given set of points\n",
        "\n",
        "    params:\n",
        "        points      [dict] of [np.array] with shape ( N, 2 )\n",
        "\n",
        "    return:\n",
        "        [float] scaling factor\n",
        "        [np.array] x and y offsets\n",
        "    \"\"\"\n",
        "    fact    = np.array( IMG_SIZE )\n",
        "    scaled  = {}\n",
        "\n",
        "    max_x   = 0.0\n",
        "    max_y   = 0.0\n",
        "    min_x   = 1.0\n",
        "    min_y   = 1.0\n",
        "    for p in points.keys():\n",
        "        # get minimum X and Y coordinates\n",
        "        mx, my      = points[ p ].min( axis=0 )\n",
        "        min_x       = min( min_x, mx )\n",
        "        min_y       = min( min_y, my )\n",
        "        # get maximum X and Y coordinates\n",
        "        mx, my      = points[ p ].max( axis=0 )\n",
        "        max_x       = max( max_x, mx )\n",
        "        max_y       = max( max_y, my )\n",
        "\n",
        "    mul     = max( max_x - min_x, max_y - min_y )   # should NOT scale X and Y differently\n",
        "    off     = np.array( ( min_x, min_y ) )          # while the offsets can differ for X and Y\n",
        "\n",
        "    return mul, off"
      ],
      "metadata": {
        "id": "4Pv-ossjKYKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_scaling( points, mul, off ):\n",
        "    \"\"\"\n",
        "    Project real points into image coordinates.\n",
        "    Rescale the coordinates to avoid the shape moving outside the figure boundaries.\n",
        "\n",
        "    params:\n",
        "        points      [dict] of [np.array] with shape ( N, 2 )\n",
        "        mul         [np.array] scaling multiplier\n",
        "        off         [np.array] scaling offset\n",
        "\n",
        "    return:\n",
        "        [dict] of [np.array] with shape ( N, 2 )\n",
        "    \"\"\"\n",
        "    fact    = np.array( IMG_SIZE )                  # image scale\n",
        "    scaled  = {}\n",
        "\n",
        "    # leave an extra empy border around the image\n",
        "    boff    = np.array( ( IMG_EDGE, IMG_EDGE ) )\n",
        "    bmul    = np.array( ( 1. - 2 * IMG_EDGE, 1. - 2 * IMG_EDGE ) )\n",
        "\n",
        "    for k in points.keys():\n",
        "        p           = points[ k ]\n",
        "        p           = ( p - off ) / mul             # scale in range 0..1\n",
        "        p           = np.array( [ 1., -1. ] ) * p   # invert Y\n",
        "        p           = np.array( [ 0.,  1. ] ) + p   # invert Y\n",
        "        p           = bmul * p + boff               # allow for border\n",
        "        p           = fact * p                      # scale up to pixels\n",
        "        scaled[ k ] = p.astype( int )               # cast to int\n",
        "\n",
        "    return scaled"
      ],
      "metadata": {
        "id": "mzfnUkpMKUqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_img( true, pred, rod1, rod2 ):\n",
        "    \"\"\"\n",
        "    Generate a single image frame comparing true and predicted shapes of a single sample\n",
        "\n",
        "    params:\n",
        "        true        [list] [ ( P1x, P1y ), ( P2x, P2y ), ( P3x, P3y ) ]\n",
        "        pred        [list] [ ( P1x, P1y ), ( P2x, P2y ), ( P3x, P3y ) ]\n",
        "        rod1        [list] [ ( A1x, A1y ), ( B1x, B1y ) ]\n",
        "        rod2        [list] [ ( A2x, A2y ), ( B2x, B2y ) ]\n",
        "\n",
        "    return:\n",
        "        [PIL.Image]\n",
        "    \"\"\"\n",
        "    img     = Image.new( 'RGB', IMG_SIZE, color=COL_BACK )\n",
        "    drw     = ImageDraw.Draw( img )\n",
        "    drw.polygon( true, fill=None, outline=COL_TRUE, width=8 )\n",
        "    drw.polygon( pred, fill=None, outline=COL_PRED, width=6 )\n",
        "    drw.polygon( rod1, fill=None, outline=COL_RODS, width=6 )\n",
        "    drw.polygon( rod2, fill=None, outline=COL_RODS, width=6 )\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "kk8LgclTKRkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_gif( trues, preds, max_frames=None ):\n",
        "    \"\"\"\n",
        "    Generate an animated GIF comparing true and predicted shapes in all given samples\n",
        "\n",
        "    params:\n",
        "        trues       [np.array] sequence of P1, P2, P3, A1, B1, A2, B2\n",
        "        preds       [np.array] sequence of P1, P2, P3\n",
        "        max_frames  [int] OPTIONAL maximum number of frames in the GIF\n",
        "    \"\"\"\n",
        "\n",
        "    # get points from ground truth\n",
        "    p_true          = {}\n",
        "    p_true[ \"p1\" ]  = trues[ :, 0:2 ]\n",
        "    p_true[ \"p2\" ]  = trues[ :, 2:4 ]\n",
        "    p_true[ \"p3\" ]  = trues[ :, 4:6 ]\n",
        "    p_true[ \"A1\" ]  = trues[ :, 6:8 ]\n",
        "    p_true[ \"B1\" ]  = trues[ :, 8:10 ]\n",
        "    p_true[ \"A2\" ]  = trues[ :, 10:12 ]\n",
        "    p_true[ \"B2\" ]  = trues[ :, 12:14 ]\n",
        "\n",
        "    # get points from predictions\n",
        "    p_pred          = {}\n",
        "    p_pred[ \"p1\" ]  = preds[ :, 0:2 ]\n",
        "    p_pred[ \"p2\" ]  = preds[ :, 2:4 ]\n",
        "    p_pred[ \"p3\" ]  = preds[ :, 4:6 ]\n",
        "\n",
        "    # rescale points\n",
        "    mul, off        = get_scaling( p_true )             # a common scalining factor for trues and preds\n",
        "    sp_true         = do_scaling( p_true, mul, off )\n",
        "    sp_pred         = do_scaling( p_pred, mul, off )\n",
        "\n",
        "    img_list        = []\n",
        "    n_frames        = len( trues ) if max_frames is None else max_frames\n",
        "\n",
        "    for i in range( n_frames ):\n",
        "        t123    = [ sp_true[ 'p1' ][ i ], sp_true[ 'p2' ][ i ], sp_true[ 'p3' ][ i ] ]\n",
        "        p123    = [ sp_pred[ 'p1' ][ i ], sp_pred[ 'p2' ][ i ], sp_pred[ 'p3' ][ i ] ]\n",
        "        r1      = [ sp_true[ 'A1' ][ i ], sp_true[ 'B1' ][ i ] ]\n",
        "        r2      = [ sp_true[ 'A2' ][ i ], sp_true[ 'B2' ][ i ] ]\n",
        "        xyt     = [ tuple( p ) for p in t123 ]\n",
        "        xyp     = [ tuple( p ) for p in p123 ]\n",
        "        xy1     = [ tuple( p ) for p in r1 ]\n",
        "        xy2     = [ tuple( p ) for p in r2 ]\n",
        "\n",
        "        img     = compare_img( xyt, xyp, xy1, xy2 )\n",
        "        img_list.append( img )\n",
        "\n",
        "    # create a GIF file\n",
        "    img_list[ 0 ].save( GIF_FILE, save_all=True, append_images=img_list[ 1: ], duration=100 )"
      ],
      "metadata": {
        "id": "fFBckISMKfFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model( nn, nfile, max_frames=None ):\n",
        "    \"\"\"\n",
        "    Test a model on one file of sequences, and show the result as a GIF.\n",
        "    The model is tested using autoregression, i.e., the prediction of step k is added to the input of step k+1\n",
        "\n",
        "    params:\n",
        "        nn          [keras.Model]\n",
        "        nfile       [int] index of the .dta file to test\n",
        "        max_frames  [int] OPTIONAL maximum number of frames in the GIF\n",
        "\n",
        "    return:\n",
        "        [np.array] original sequence of P1, P2, P3\n",
        "        [np.array] predicted sequence of P1, P2, P3\n",
        "    \"\"\"\n",
        "    print( f\"Now starting testing on file #{nfile}...\\n\" )\n",
        "\n",
        "    points_all  = read_file_pend( nfile, points_only=False )    # P1, P2, P3, A1, B1, A2, B2\n",
        "    points      = points_all[ :, :6 ]                           # P1, P2, P3\n",
        "    n_points    = len( points )\n",
        "\n",
        "    preds       = points.copy()                                 # temporary holder for predictions\n",
        "\n",
        "    # the input sequence is initialized with all original points\n",
        "    x           = points[ : SEQ_LEN ]\n",
        "\n",
        "    for i in range( n_points - SEQ_LEN ):\n",
        "        y                       = nn.model( x[ np.newaxis, ... ] )  # add batch size\n",
        "        y                       = y[ 0 ].numpy()\n",
        "        preds[ i + SEQ_LEN ]    = y                                 # save the current prediction\n",
        "\n",
        "        # the next input is previous one shifted by one position...\n",
        "        x       = np.roll( x, -1, axis=0 )\n",
        "        # ...with the last element being the current prediction\n",
        "        x[ -1 ] = y\n",
        "\n",
        "    # save the result as GIF\n",
        "    compare_gif( points_all, preds, max_frames=max_frames )\n",
        "\n",
        "    return points, preds"
      ],
      "metadata": {
        "id": "DvxQZJvaFZnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ],
      "metadata": {
        "id": "ttyGtLr2Lseh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN   = False"
      ],
      "metadata": {
        "id": "SspvlhAHMcH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn                  = TransDecoder()\n",
        "train_set, test_set = create_dset()\n",
        "\n",
        "if TRAIN:\n",
        "    nn, hist        = train_model( nn, train_set, test_set )\n",
        "else:\n",
        "    nn.model.load_weights( nn_t2v )"
      ],
      "metadata": {
        "id": "GMBMke7sKyTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NSEQ            = 9\n",
        "MFRM            = 150\n",
        "points, pred    = test_model( nn, nfile=NSEQ, max_frames=MFRM )"
      ],
      "metadata": {
        "id": "_eIfjpKsSHsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the GIF\n",
        "IPythonImage( open( GIF_FILE, 'rb' ).read() )"
      ],
      "metadata": {
        "id": "-MSbiPAsOJHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}