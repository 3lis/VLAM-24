{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRuRG/kBpODaUIrtWh5fBL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KmWuU3Zu2C-_","executionInfo":{"status":"ok","timestamp":1709719328073,"user_tz":-60,"elapsed":4024,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"outputs":[],"source":["import  os\n","import  sys\n","import  platform\n","import  time\n","import  datetime\n","import  pickle\n","\n","import  numpy                   as np\n","import  pandas                  as pd\n","from    PIL                     import Image, ImageDraw\n","from    IPython.display         import Image    as IPythonImage\n","\n","from    argparse                import ArgumentParser\n","import  matplotlib.pyplot       as plt\n","import  matplotlib.image        as mpimg\n","\n","import  tensorflow              as tf\n","from    tensorflow              import keras\n","from    tensorflow.keras        import utils\n","from    tensorflow.keras        import backend  as K\n","from    tensorflow.keras.layers import Layer"]},{"cell_type":"markdown","source":["# Pendulum"],"metadata":{"id":"PB1o0PY4-JDN"}},{"cell_type":"markdown","source":["## Data Reading"],"metadata":{"id":"KF9eDPWp-LEy"}},{"cell_type":"code","source":["inp_zip     = \"pend.zip\"\n","inp_path    = \"GeneralisedPendulum\"         # path and prefix of the input data files\n","header      = 3                                     # line with header in the input data files\n","\n","# partitioning of the data to be generated\n","train_test  = {\n","    'train' : [ 8, 10, 11, 13, 15, 16, 18 ],\n","    'test'  : [ 9, 14, 17 ]\n","}"],"metadata":{"id":"Kjev97TL-6UC","executionInfo":{"status":"ok","timestamp":1709719328074,"user_tz":-60,"elapsed":9,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!wget -O {inp_zip} https://www.dropbox.com/scl/fi/ell5z8bje172n0c6st0e3/pend.zip?rlkey=t5mxsl2cev6xbugogcd3ej028&dl=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYcb5Jnk_2cU","executionInfo":{"status":"ok","timestamp":1709719329301,"user_tz":-60,"elapsed":1235,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"fd018d1d-976a-4e5e-eee3-fb38799ecb28"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-06 10:02:07--  https://www.dropbox.com/scl/fi/ell5z8bje172n0c6st0e3/pend.zip?rlkey=t5mxsl2cev6xbugogcd3ej028\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6019:18::a27d:412\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc8cc03045298791e23140764936.dl.dropboxusercontent.com/cd/0/inline/COnM_FG66GTYnr5FKeKtTT32RcEqxr4ibZ75Ksrh77qVDaety_y0AXTnDumVAVJl6Jje_ZWQIKhRQRuS2tKFtVZe_4YaO-kBN600UDrbdzHkuI2iC1obDyOkl2DXwksdTnA/file# [following]\n","--2024-03-06 10:02:08--  https://uc8cc03045298791e23140764936.dl.dropboxusercontent.com/cd/0/inline/COnM_FG66GTYnr5FKeKtTT32RcEqxr4ibZ75Ksrh77qVDaety_y0AXTnDumVAVJl6Jje_ZWQIKhRQRuS2tKFtVZe_4YaO-kBN600UDrbdzHkuI2iC1obDyOkl2DXwksdTnA/file\n","Resolving uc8cc03045298791e23140764936.dl.dropboxusercontent.com (uc8cc03045298791e23140764936.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:6019:15::a27d:40f\n","Connecting to uc8cc03045298791e23140764936.dl.dropboxusercontent.com (uc8cc03045298791e23140764936.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/COmvv4hVIwU_6t0CbWVGvDlGArahBkXR21WmqNxtXq907yJRzkJcv7yDwQ2MO7CJHqC8qsjC7Q5nO3pCxkb8QMfX2QSWUPEt6cYyXxeIQf1u7NO706K-AcWhykd4Dbf75Qhbu-SKL78gvonRrcEDTN2DnS7AQD7r6GIqNB3A6vsZd50--hLAeqVAxXysDmud92KEnd7m8e5F-gyyy16619t1Y-jrjaENLjPKDdQu5eaN1bXC5HlHIqRr-Pwr0-BaBqzAUsVEJxIk2tLtbOIFb9ffE-Yx6ePcArySX7zl3LpIS6HCdsXwsUqjClLtz59oJQN40HL9I71Mua-jCkdRX-_wLMH1lTFl-wHi76VYCS4g2g/file [following]\n","--2024-03-06 10:02:08--  https://uc8cc03045298791e23140764936.dl.dropboxusercontent.com/cd/0/inline2/COmvv4hVIwU_6t0CbWVGvDlGArahBkXR21WmqNxtXq907yJRzkJcv7yDwQ2MO7CJHqC8qsjC7Q5nO3pCxkb8QMfX2QSWUPEt6cYyXxeIQf1u7NO706K-AcWhykd4Dbf75Qhbu-SKL78gvonRrcEDTN2DnS7AQD7r6GIqNB3A6vsZd50--hLAeqVAxXysDmud92KEnd7m8e5F-gyyy16619t1Y-jrjaENLjPKDdQu5eaN1bXC5HlHIqRr-Pwr0-BaBqzAUsVEJxIk2tLtbOIFb9ffE-Yx6ePcArySX7zl3LpIS6HCdsXwsUqjClLtz59oJQN40HL9I71Mua-jCkdRX-_wLMH1lTFl-wHi76VYCS4g2g/file\n","Reusing existing connection to uc8cc03045298791e23140764936.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 108750 (106K) [application/zip]\n","Saving to: ‘pend.zip’\n","\n","pend.zip            100%[===================>] 106.20K  --.-KB/s    in 0.006s  \n","\n","2024-03-06 10:02:08 (17.7 MB/s) - ‘pend.zip’ saved [108750/108750]\n","\n"]}]},{"cell_type":"code","source":["!mkdir {inp_path}\n","!unzip {inp_zip} -d {inp_path}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIcxxZlT_7JV","executionInfo":{"status":"ok","timestamp":1709719329724,"user_tz":-60,"elapsed":427,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"5016b827-c038-40bc-9a9e-cb06731e7bd1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  pend.zip\n","  inflating: GeneralisedPendulum/GeneralisedPendulum08.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum09.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum10.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum11.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum13.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum14.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum15.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum16.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum17.dta  \n","  inflating: GeneralisedPendulum/GeneralisedPendulum18.dta  \n"]}]},{"cell_type":"code","source":["def read_file_pend( n, points_only=True ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    read the file with the given number in the filename and return a list with the array of coordinates\n","    of the 3 points in time\n","\n","    n:              [int] number of the file\n","\n","    return:         np.array with time as first dimension, and points p1, p2, p3 coordinates\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","\n","    f           = \"{}/GeneralisedPendulum{:02d}.dta\".format( inp_path, n )\n","    assert os.path.isfile( f ), \"data file {} not found\".format( f )\n","    r           = pd.read_csv( f, sep='\\t', header=header )\n","\n","    if points_only:\n","        points      = np.array( [\n","                r[ 'x1' ],  r[ 'y1' ],\n","                r[ 'x2' ],  r[ 'y2' ],\n","                r[ 'x3' ],  r[ 'y3' ]\n","        ] ).T\n","\n","    else:\n","        points      = np.array( [\n","                r[ 'x1' ],  r[ 'y1' ],\n","                r[ 'x2' ],  r[ 'y2' ],\n","                r[ 'x3' ],  r[ 'y3' ],\n","                r[ 'A1x' ], r[ 'A1y' ],\n","                r[ 'B1x' ], r[ 'B1y' ],\n","                r[ 'A2x' ], r[ 'A2y' ],\n","                r[ 'B2x' ], r[ 'B2y' ]\n","        ] ).T\n","\n","    return points"],"metadata":{"id":"l7tS8jlf-S08","executionInfo":{"status":"ok","timestamp":1709719329725,"user_tz":-60,"elapsed":8,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def gen_sequences( files, seq_len=20, down=1, batch_size=32, train=True ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    construct a data generator that takes seq_len elements as input, and the following lement as target\n","    concatenate datasets over all requested files\n","\n","    files:          [list] of numbers of the data files\n","    seq_len:        [int] length of the sequence of images\n","    down:           [int] downsamplig factor, when down=1 all possible sequences will be generated, half with down=2...\n","\n","    return:         [tf.data.Dataset] that yelds a tuple with batch of inputs and batch of targets\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    if train:\n","        tr_ts   = 'train'\n","    else:\n","        tr_ts   = 'test'\n","    files   = train_test[ tr_ts ]\n","\n","    dset    = None\n","    for n in files:\n","        p       = read_file_pend( n )\n","        inp     = p[ : -seq_len ]       # discard the last elements in the serie for the inputs\n","        target  = p[ seq_len: ]         # discard the first elements in the serie for the targets\n","        d       = utils.timeseries_dataset_from_array(\n","                inp,\n","                target,\n","                sequence_length = seq_len,\n","                sequence_stride = down,\n","                batch_size      = batch_size,\n","                shuffle         = train\n","        )\n","        if dset is None:\n","            dset    = d\n","        else:\n","            dset    = dset.concatenate( d )\n","\n","    return dset"],"metadata":{"id":"-0K4vMaQAt-V","executionInfo":{"status":"ok","timestamp":1709719329725,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def gen_dset_pend( seq_len=20, down=1, batch_size=32 ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    generated the training and test sets\n","\n","    seq_len:        [int] length of the sequence of images\n","    down:           [int] downsamplig factor, when down=1 all possible sequences will be generated, half with down=2...\n","\n","    return:         [tuple] with training and test datasets\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    files   = train_test[ \"train\" ]\n","    tr_set  = gen_sequences( files, seq_len=seq_len, down=down, batch_size=batch_size, train=True )\n","    files   = train_test[ \"test\" ]\n","    ts_set  = gen_sequences( files, seq_len=seq_len, down=down, batch_size=batch_size, train=False )\n","\n","    return tr_set, ts_set"],"metadata":{"id":"fdK-korRAw24","executionInfo":{"status":"ok","timestamp":1709719329725,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Parameters"],"metadata":{"id":"EwPgjUJJEHNy"}},{"cell_type":"code","source":["FRMT                    = \"%y-%m-%d_%H-%M-%S\"   # datetime format for folder names\n","\n","\n","# folders and files inside the main execution folder - NOTE the variables will be updated in init_dirs()\n","dir_current         \t= None\n","dir_res             \t= '../res'              # where all results are stored\n","dir_test            \t= 'test'                # where all results are stored\n","nn_final            \t= \"nn_final.h5\"         # the name of the trained model weights\n","nn_graph            \t= \"nn.png\"              # the graph of the model\n","gif_file                = \"output.gif\"\n","\n","BATCH_SIZE              = 16                    # batch size of the generator\n","N_EPOCHS                = 2                     # number of training epochs\n","LRATE                   = 0.001                 # learning rate\n","DROPOUT                 = 0.2                   # dropout probability during training of attention\n","NUM_HEADS               = 4                     # number of attention heads\n","SEQ_LEN                 = 40                    # length of the time sequence before the prediction\n","DOWNSAMPLE              = 1                     # downsamplig factor, with down=1 keep all sequences\n","DATA_DIM                = 6                     # dimension of a data sample (2D coordinates for 3 points)\n","EMBED_DIM               = 64                    # embedding dimension\n","EMBED_MODE              = 'time2vec'            # embedding modality - current options are:\n","                                                #   \"conv1d\"    use 1D convolution\n","                                                #   None        no embedding at all\n","                                                #   \"time2vec\"  use Time2Vec"],"metadata":{"id":"UoiY1j8kEK08","executionInfo":{"status":"ok","timestamp":1709719329725,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Time2Vec"],"metadata":{"id":"b2Mq_aVXD2B6"}},{"cell_type":"code","source":["class Time2Vec( Layer ):\n","    \"\"\"\n","    this class implements  Kazemi et al,'s Time2Vec layer, to be used as possible embedding\n","    \"\"\"\n","\n","    def __init__( self, **kwargs ):\n","        \"\"\"\n","        initialization of the class\n","        \"\"\"\n","        super().__init__( **kwargs )\n","        self.inp_dim    = DATA_DIM\n","        self.dim        = EMBED_DIM\n","\n","\n","    def build( self, input_shape ):\n","        \"\"\"\n","        define all trainable weights\n","        NOTE a certain pedantry in assigning names to each component\n","        it has been necessary to get rid of \"ValueError: Unable to create dataset (name already exists)\"\n","        when executing model.save_weights()\n","        \"\"\"\n","        self.wa         = self.add_weight(\n","            shape           = ( self.inp_dim, self.dim - 1 ),\n","            initializer     = 'uniform',\n","            name            = \"WeightT2VLinearMatrix\",\n","            trainable       = True\n","        )\n","        self.ba         = self.add_weight(\n","            shape=( 1, self.dim - 1 ),\n","            initializer     = 'uniform',\n","            name            = \"WeightT2VLinearOffset\",\n","            trainable       = True\n","        )\n","        self.wb         = self.add_weight(\n","            shape=( self.inp_dim, 1 ),\n","            initializer     = 'uniform',\n","            name            = \"WeightT2VPeriodicMatrix\",\n","            trainable       = True\n","        )\n","        self.bb         = self.add_weight(\n","            shape=( 1, 1 ),\n","            initializer     = 'uniform',\n","            name            = \"WeightT2VPeriodicOffset\",\n","            trainable       = True\n","        )\n","\n","\n","    def call( self, inputs ):\n","        \"\"\"\n","        execute the Time2Vec computation\n","        NOTE the specifications in the tf.tensordot multiplication, for eliminating the\n","        original dimensions of the tensors (the 6 points coordinates), obtaining the\n","        desired embedding dimension\n","        \"\"\"\n","        linear          = tf.tensordot( inputs, self.wb, axes=( (-1), (0) ) )\n","        linear          += self.bb\n","        periodic        = tf.tensordot( inputs, self.wa, axes=( (-1), (0) ) )\n","        periodic        += self.ba\n","        periodic        = tf.math.sin( periodic )\n","        t2v             = tf.concat( [ linear, periodic ], -1 )\n","        return t2v"],"metadata":{"id":"eN1LV2esD1KT","executionInfo":{"status":"ok","timestamp":1709719329726,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## TransformerDecoder"],"metadata":{"id":"n86iUt9-FA8I"}},{"cell_type":"code","source":["class TransDecoder( object ):\n","    \"\"\"\n","    this class implements an essential Transformer decoder\n","    NOTE there is already in Keras a TransformerDecoder layer, but by building it in pieces it is possible\n","    to isolate the part that implements attention, in order to exctract and visualize attention results\n","    \"\"\"\n","\n","    def __init__( self ):\n","        \"\"\"\n","        initialization of the class\n","        \"\"\"\n","        self.num_heads  = NUM_HEADS\n","        self.lenght     = SEQ_LEN\n","        self.inp_dim    = DATA_DIM\n","        if TRAIN:\n","            self.dropout    = DROPOUT\n","        else:\n","            self.dropout    = 0.0\n","        if EMBED_MODE is None:\n","            self.dim        = self.inp_dim\n","            self.embedding  = self._noembedding()\n","        elif EMBED_MODE == \"conv1d\":\n","            self.dim        = EMBED_DIM\n","            self.embedding  = self._conv_embed()\n","        elif EMBED_MODE == \"time2vec\":\n","            self.dim        = EMBED_DIM\n","            self.embedding  = self._t2v_embed()\n","        self.loss_func  = keras.losses.MeanSquaredError()\n","        self.key_dim    = self.dim // self.num_heads\n","        self.attention  = self._attention()\n","        self.model      = self.create_model()\n","\n","\n","    def _noembedding( self ):\n","        \"\"\"\n","        do not use any embedding\n","        \"\"\"\n","        embedding   = lambda x: x\n","        return embedding\n","\n","\n","    def _conv_embed( self ):\n","        \"\"\"\n","        used conv1D as embedding, in order to apply the same matrix to all vectors in the sequence\n","        \"\"\"\n","        embedding   = keras.layers.Conv1D( self.dim, kernel_size=1, name=\"Conv1DEmbed\" )\n","        return embedding\n","\n","\n","    def _t2v_embed( self ):\n","        \"\"\"\n","        used Time2Vec as embedding, note the necessary transformation of input shape\n","        \"\"\"\n","        return Time2Vec( name=\"Time2VecEmbed\" )\n","\n","\n","    def _loss_func( self, y_true, y_pred ):\n","        \"\"\"\n","        define the loss function for the case when the output of the model is as embedded vector\n","        \"\"\"\n","        msq     = keras.losses.MeanSquaredError()\n","        y_true  = tf.expand_dims( y_true, axis=0 )\n","        return msq( self.embedding( y_true ), y_pred )\n","\n","\n","    def _attention( self ):\n","        \"\"\"\n","        define the attention part of the model\n","        \"\"\"\n","        att         = keras.layers.MultiHeadAttention(\n","                num_heads   = self.num_heads,\n","                key_dim     = self.key_dim,\n","                dropout     = self.dropout,\n","                name        = \"MHAttention\"\n","        )\n","        return att\n","\n","\n","    def create_model( self ):\n","        \"\"\"\n","        create the model\n","        \"\"\"\n","\n","        inputs      = keras.layers.Input( shape=( self.lenght, self.inp_dim ), dtype=tf.float32 )\n","        x           = self.embedding( inputs )\n","        x           = self.attention( x, x )\n","        x           = keras.layers.LayerNormalization( name=\"NormLayer\" )( x )\n","        # note that the Dense output has shape batch_size X lenght X inp_dim\n","        x           = keras.layers.Dense( self.inp_dim, activation='sigmoid', name=\"Dense1\" )( x )\n","        x           = keras.layers.Flatten( name=\"FlattenDense\" )( x )\n","        outputs     = keras.layers.Dense( self.inp_dim, name=\"Dense2\" )( x )\n","        model       = keras.Model(inputs=inputs, outputs=outputs)\n","\n","        return model"],"metadata":{"id":"6OadJMHqFDBw","executionInfo":{"status":"ok","timestamp":1709719329726,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Main functions"],"metadata":{"id":"DrWwMZrWFOf_"}},{"cell_type":"code","source":["def create_dset():\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    create the datasets for training and validation\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    # global train_set, test_set\n","    print( \"Now creating the datasets...\\n\" )\n","    train_set, test_set = gen_dset_pend(\n","            seq_len     = SEQ_LEN,\n","            down        = DOWNSAMPLE,\n","            batch_size  = BATCH_SIZE\n","    )\n","    return train_set, test_set"],"metadata":{"id":"rkjGFDGiFQUV","executionInfo":{"status":"ok","timestamp":1709719329726,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def train_model( nn, train_set, test_set ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    train the model and save the weigths\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    # global train_set, test_set\n","\n","    nn.model.compile(\n","            optimizer   = keras.optimizers.Adam( learning_rate=LRATE ),\n","            loss        = nn.loss_func,\n","            metrics     = [ 'accuracy' ]\n","    )\n","    hist        = nn.model.fit(\n","            x                   = train_set,\n","            validation_data     = test_set,\n","            epochs              = N_EPOCHS,\n","            verbose             = 1\n","    )\n","\n","    # save the model and its graph\n","    nn.model.save_weights( nn_final )\n","    keras.utils.plot_model( nn.model, to_file=nn_graph, show_shapes=True, show_layer_names=True )\n","\n","    return nn, hist"],"metadata":{"id":"dhm6XKUIFW7s","executionInfo":{"status":"ok","timestamp":1709719329726,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def test_model( nn, nfile=8 ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    test the model on one file of sequences, and represent the rsults as images\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    print( f\"Now starting testing on file {nfile}...\\n\" )\n","\n","    points_all  = read_file_pend( nfile, points_only=False )\n","    points      = points_all[ :, :6 ]\n","\n","    preds       = points.copy()\n","    slen        = SEQ_LEN\n","    npts        = len( points )\n","\n","    # now in a loop a full sequence is presented, and the model predict the next\n","    # trajectory, then the sequnce is shifted in time, with the last element filled with\n","    # the prediction\n","    x           = points[ : slen ]      # prepare the first sequence, all made by original points\n","    for i in range( npts - slen ):\n","        y                   = nn.model( x[ np.newaxis, ... ] )\n","        y                   = y[ 0 ].numpy()\n","        preds[ i + slen ]   = y         # save the current prediction\n","        x                   = np.roll( x, -1, axis=0 )\n","        x[ -1 ]             = y         # the last element of the sequence is the prediction\n","\n","    # call the graphic function that generate the images\n","    gen_compare( points_all, preds, nfile, gif_file )\n","    IPythonImage( open( gif_file, 'rb' ).read() )\n","\n","    return points, preds"],"metadata":{"id":"DvxQZJvaFZnU","executionInfo":{"status":"ok","timestamp":1709719329726,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Image output generation"],"metadata":{"id":"gE4UvD_cGsfu"}},{"cell_type":"code","source":["isize       = ( 256, 256 )                          # image size\n","\n","img_dir     = \"imgs/\"                               # output images directory\n","background  = 20                                    # background gray level\n","foreground  = 160                                   # object filling gray level\n","linecolor   = 210                                   # object edge gray level\n","edgecolor   = 250                                   # object edge gray level\n","fore_true   = \"#00b000\"\n","edge_true   = \"#00ff00\"\n","fore_pred   = \"#b00080\"\n","edge_pred   = \"#ff0000\"\n","border      = 0.15                                  # minimum border of the trajectories, as fraction of 1.0\n","\n","# numbers of existing and valid files\n","valid_files = [ 8, 9, 10, 11, 13, 14, 15, 16, 17, 18 ]"],"metadata":{"id":"DR1EkJ6MGydh","executionInfo":{"status":"ok","timestamp":1709719329975,"user_tz":-60,"elapsed":254,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def read_file_test( n ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    read the file with the given number in the filename\n","\n","    n:              [int] number of the file\n","\n","    return:         [dict] [ with keys \"p1\", \"p2\", \"p3\", \"A1\", \"B1\", \"A2\", \"B2\" and np.arrays as values ]\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","\n","    f           = \"{}{:02d}.dta\".format( inp_path, n )\n","    assert os.path.isfile( f ), f\"data file {f} not found\"\n","\n","    r           = pd.read_csv( f, sep='\\t', header=header )\n","    d           = {}\n","    d[ 'p1' ]   = np.array( [ r[ 'x1' ], r[ 'y1' ] ] ).T\n","    d[ 'p2' ]   = np.array( [ r[ 'x2' ], r[ 'y2' ] ] ).T\n","    d[ 'p3' ]   = np.array( [ r[ 'x3' ], r[ 'y3' ] ] ).T\n","    d[ 'A1' ]   = np.array( [ r[ 'A1x' ], r[ 'A1y' ] ] ).T\n","    d[ 'B1' ]   = np.array( [ r[ 'B1x' ], r[ 'B1y' ] ] ).T\n","    d[ 'A2' ]   = np.array( [ r[ 'A2x' ], r[ 'A2y' ] ] ).T\n","    d[ 'B2' ]   = np.array( [ r[ 'B2x' ], r[ 'B2y' ] ] ).T\n","\n","    return d"],"metadata":{"id":"XjhhmKvVKHlr","executionInfo":{"status":"ok","timestamp":1709719329976,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def scale( points, mul, off ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    scale points from real to image coordinates, avoiding the figure to move out of the boundaries\n","\n","    points:         [dict] of np.array with shape ( N, 2 )\n","    mul:            [np.array] scaling multiplier\n","    off:            [np.array] scaling offset\n","\n","    return:         [dict] of np.array with shape ( N, 2 )\n","\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","\n","    fact    = np.array( isize )\n","    scaled  = {}\n","\n","    boff    = np.array( ( border, border ) )        # take some border for the trajectories\n","    bmul    = np.array( ( 1. - 2 * border, 1. - 2 * border ) )\n","    for k in points.keys():\n","        p           = points[ k ]\n","        p           = ( p - off ) / mul             # scale in range 0..1\n","        p           = np.array( [ 1., -1. ] ) * p   # invert Y\n","        p           = np.array( [ 0.,  1. ] ) + p   # invert Y\n","        p           = bmul * p + boff               # allow for borders\n","        p           = fact * p                      # scale up to pixels\n","        scaled[ k ] = p.astype( int )\n","\n","    return scaled"],"metadata":{"id":"mzfnUkpMKUqg","executionInfo":{"status":"ok","timestamp":1709719329976,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def scaling( points ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    computing the scaling factors for a given set of points\n","\n","    points:         [dict] of np.array with shape ( N, 2 )\n","\n","    return:         [tuple] mul, off\n","\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","    fact    = np.array( isize )\n","    scaled  = {}\n","\n","    max_x   = 0.0\n","    max_y   = 0.0\n","    min_x   = 1.0\n","    min_y   = 1.0\n","    for p in points.keys():\n","        mx, my      = points[ p ].min( axis=0 )\n","        min_x       = min( min_x, mx )\n","        min_y       = min( min_y, my )\n","        mx, my      = points[ p ].max( axis=0 )\n","        max_x       = max( max_x, mx )\n","        max_y       = max( max_y, my )\n","\n","    mul     = max( max_x - min_x, max_y - min_y )   # note: should NOT scale X and Y differently\n","    off     = np.array( ( min_x, min_y ) )          # while the offsets can differ for X and Y\n","\n","    return mul, off"],"metadata":{"id":"4Pv-ossjKYKJ","executionInfo":{"status":"ok","timestamp":1709719329976,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def draw_compare( true, preds, rod1, rod2 ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    draw one frame with true and predicted triangles\n","\n","    f:              [str] filename\n","    true:           [list] [ ( p1x, p1y ), ( p2x, p2y ), ( p3x, p3y ) ]\n","    preds:          [list] [ ( p1x, p1y ), ( p2x, p2y ), ( p3x, p3y ) ]\n","\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","\n","    img     = Image.new( 'RGB', isize, color=background )\n","    drw     = ImageDraw.Draw( img )\n","    drw.polygon( true, fill=None, outline=edge_true, width=8 )\n","    drw.polygon( preds, fill=None, outline=edge_pred, width=6 )\n","    drw.polygon( rod1, fill=None, outline=\"#ffffff\", width=6 )\n","    drw.polygon( rod2, fill=None, outline=\"#ffffff\", width=6 )\n","\n","    return img"],"metadata":{"id":"kk8LgclTKRkj","executionInfo":{"status":"ok","timestamp":1709719329976,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def gen_compare( points, preds, n, fname ):\n","    \"\"\" -------------------------------------------------------------------------------------------------------------\n","    generate frames for one file\n","\n","    n:              [int] number of the file\n","    points:         [dict] { p1, p2, p3, A1, B1, A2, B2 } as returned by read_file_test()\n","    ------------------------------------------------------------------------------------------------------------- \"\"\"\n","\n","    n_frames        = len( points )                             # extract number of time samples\n","    p_true          = {}\n","    p_pred          = {}\n","    p_rod1          = {}\n","    p_rod2          = {}\n","    p_true[ \"p1\" ]  = points[ :, 0:2 ]\n","    p_true[ \"p2\" ]  = points[ :, 2:4 ]\n","    p_true[ \"p3\" ]  = points[ :, 4:6 ]\n","    p_pred[ \"p1\" ]  = preds[ :, 0:2 ]\n","    p_pred[ \"p2\" ]  = preds[ :, 2:4 ]\n","    p_pred[ \"p3\" ]  = preds[ :, 4:6 ]\n","    p_true[ \"A1\" ]  = points[ :, 6:8 ]\n","    p_true[ \"B1\" ]  = points[ :, 8:10 ]\n","    p_true[ \"A2\" ]  = points[ :, 10:12 ]\n","    p_true[ \"B2\" ]  = points[ :, 12:14 ]\n","\n","    mul, off        = scaling( p_true )                         # compute the proper scaling\n","    sp_true         = scale( p_true, mul, off )                 # scaled points\n","    sp_pred         = scale( p_pred, mul, off )                 # scaled points\n","\n","    img_list        = []\n","\n","    for i in range( n_frames ):\n","        t123    = [ sp_true[ 'p1' ][ i ], sp_true[ 'p2' ][ i ], sp_true[ 'p3' ][ i ] ]\n","        p123    = [ sp_pred[ 'p1' ][ i ], sp_pred[ 'p2' ][ i ], sp_pred[ 'p3' ][ i ] ]\n","        r1      = [ sp_true[ 'A1' ][ i ], sp_true[ 'B1' ][ i ] ]\n","        r2      = [ sp_true[ 'A2' ][ i ], sp_true[ 'B2' ][ i ] ]\n","        xyt     = [ tuple( p ) for p in t123 ]\n","        xyp     = [ tuple( p ) for p in p123 ]\n","        xy1     = [ tuple( p ) for p in r1 ]\n","        xy2     = [ tuple( p ) for p in r2 ]\n","\n","        img     = draw_compare( xyt, xyp, xy1, xy2 )\n","        img_list.append( img )\n","\n","    img_list[ 0 ].save( fname, save_all=True, append_images=img_list[ 1: ], duration=100, loop=0 )"],"metadata":{"id":"fFBckISMKfFV","executionInfo":{"status":"ok","timestamp":1709719329976,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## Usage"],"metadata":{"id":"ttyGtLr2Lseh"}},{"cell_type":"code","source":["nn_t2v  = \"pend_t2v_e2000.h5\"\n","!wget -O {nn_t2v} https://www.dropbox.com/scl/fi/fgsfklo5z944acm6l0nu3/pend_t2v_e2000.h5?rlkey=ej6uqo6tpggmtn204r88vg6fu&dl=0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMrvLTohvFQD","executionInfo":{"status":"ok","timestamp":1709719331207,"user_tz":-60,"elapsed":1235,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"3da5cb95-db36-4f1d-90f4-7895409bb8d4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-03-06 10:02:09--  https://www.dropbox.com/scl/fi/fgsfklo5z944acm6l0nu3/pend_t2v_e2000.h5?rlkey=ej6uqo6tpggmtn204r88vg6fu\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6030:18::a27d:5012\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com/cd/0/inline/COlhRsa8JrPrZNN-0FvS6hJvQxSF_FwkdDIA70d9N1vF8ugfEkdXay7rVikqsDkxMjU0kdyVMsLqT8DU6b3BVgdj_aVgga_0YKISoxfZbrgiImqeGk2qHHgZB9eNLCDeCJw/file# [following]\n","--2024-03-06 10:02:10--  https://uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com/cd/0/inline/COlhRsa8JrPrZNN-0FvS6hJvQxSF_FwkdDIA70d9N1vF8ugfEkdXay7rVikqsDkxMjU0kdyVMsLqT8DU6b3BVgdj_aVgga_0YKISoxfZbrgiImqeGk2qHHgZB9eNLCDeCJw/file\n","Resolving uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com (uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6019:15::a27d:40f\n","Connecting to uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com (uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /cd/0/inline2/COkI0jh-eSU3BC4WZwzK36XAcOpoW6SmoK5e3aVm6sV7gUrirSHqDzqweMwmdMvfRPqwQe05rSDET_E5S7gb0xyETUveh9LeSR01Aj05Cksjwz6rlXTKuk3OfPzQ6qzpZC9WgWcr89d6mpLx-Et6_jAgZDcePtjeVJ3-O1RI5pSlyuLcAnBQXw7BCwO057cqg2vIgMVBeijD3L3NJ0qnC75Axw2amULa3gpAdvUbYmWBj8QOTDAt4lSffcAatAC29mPvLPLvLfJaccQ-qiriWN7VveVZ-ugehBrRL0QTLBClO0KUxTKx37q-XyVOy0Yog-ugzJ9TGZy2aJxtGOBRiWXkrW7Gp4nhEv4j6tmC7ycSKg/file [following]\n","--2024-03-06 10:02:10--  https://uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com/cd/0/inline2/COkI0jh-eSU3BC4WZwzK36XAcOpoW6SmoK5e3aVm6sV7gUrirSHqDzqweMwmdMvfRPqwQe05rSDET_E5S7gb0xyETUveh9LeSR01Aj05Cksjwz6rlXTKuk3OfPzQ6qzpZC9WgWcr89d6mpLx-Et6_jAgZDcePtjeVJ3-O1RI5pSlyuLcAnBQXw7BCwO057cqg2vIgMVBeijD3L3NJ0qnC75Axw2amULa3gpAdvUbYmWBj8QOTDAt4lSffcAatAC29mPvLPLvLfJaccQ-qiriWN7VveVZ-ugehBrRL0QTLBClO0KUxTKx37q-XyVOy0Yog-ugzJ9TGZy2aJxtGOBRiWXkrW7Gp4nhEv4j6tmC7ycSKg/file\n","Reusing existing connection to uc4c60ead54581db9e33b64a1d09.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 105952 (103K) [application/octet-stream]\n","Saving to: ‘pend_t2v_e2000.h5’\n","\n","pend_t2v_e2000.h5   100%[===================>] 103.47K  --.-KB/s    in 0.02s   \n","\n","2024-03-06 10:02:11 (4.73 MB/s) - ‘pend_t2v_e2000.h5’ saved [105952/105952]\n","\n"]}]},{"cell_type":"code","source":["dir_test    = \"test\"\n","if not os.path.exists( dir_test ):\n","    os.makedirs( dir_test )"],"metadata":{"id":"FzRP6q0DVbMc","executionInfo":{"status":"ok","timestamp":1709719331617,"user_tz":-60,"elapsed":412,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["TRAIN   = False"],"metadata":{"id":"SspvlhAHMcH4","executionInfo":{"status":"ok","timestamp":1709719331617,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["nn      = TransDecoder()"],"metadata":{"id":"GMBMke7sKyTq","executionInfo":{"status":"ok","timestamp":1709719332726,"user_tz":-60,"elapsed":1112,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_set, test_set = create_dset()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6srUHQlMwMR","executionInfo":{"status":"ok","timestamp":1709719335532,"user_tz":-60,"elapsed":2808,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"6978f1b6-4ca2-4c70-d9c6-cad2a4597f40"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Now creating the datasets...\n","\n"]}]},{"cell_type":"code","source":["# train\n","# nn, hist    = train_model( nn, train_set, test_set )"],"metadata":{"id":"qY85b4rrOJA-","executionInfo":{"status":"ok","timestamp":1709719335533,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# load model\n","\n","nn.model.load_weights( nn_t2v )"],"metadata":{"id":"QO1BD1vgvWN-","executionInfo":{"status":"ok","timestamp":1709719335533,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["NSEQ    = 8"],"metadata":{"id":"2eLiknVSSDY4","executionInfo":{"status":"ok","timestamp":1709719335533,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["points, pred    = test_model( nn, nfile=NSEQ )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eIfjpKsSHsX","executionInfo":{"status":"ok","timestamp":1709719356631,"user_tz":-60,"elapsed":21102,"user":{"displayName":"Alice Plebe","userId":"01290901716087727689"}},"outputId":"6dc6d905-662e-409c-b11e-a55e26c6b54b"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Now starting testing on file 8...\n","\n"]}]},{"cell_type":"code","source":["IPythonImage( open( gif_file, 'rb' ).read() )"],"metadata":{"id":"-MSbiPAsOJHe"},"execution_count":null,"outputs":[]}]}