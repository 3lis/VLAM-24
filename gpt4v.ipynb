{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw_H4Aonmsc-"
      },
      "outputs": [],
      "source": [
        "!pip install openai==1.14.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0_XG1NBqxYP"
      },
      "outputs": [],
      "source": [
        "from    IPython.display     import Image\n",
        "import  base64\n",
        "import  time\n",
        "import  matplotlib.pyplot   as plt\n",
        "import  matplotlib.image    as mpimg\n",
        "from    openai              import OpenAI, RateLimitError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpKwSBqZmkvS"
      },
      "outputs": [],
      "source": [
        "# get the API key from Colab Secrets\n",
        "from    google.colab        import userdata, widgets\n",
        "KEY     = userdata.get( 'OA_TOKEN_P' )\n",
        "\n",
        "# set the API key in the OpenAI client\n",
        "client          = OpenAI( api_key=KEY )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data download"
      ],
      "metadata": {
        "id": "r9WF0HK7A6oF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_image_1  = \"img1.jpg\"\n",
        "my_image_2  = \"img2.jpg\"\n",
        "my_image_3  = \"img3.jpg\"\n",
        "my_image_4  = \"img4.jpg\"\n",
        "\n",
        "!wget -O {my_image_1} https://www.dropbox.com/scl/fi/5fkn00h925xjf51jcodcj/c1.jpg?rlkey=2a7kjoqphqaz5mt1wl3c5bp4i&dl=0\n",
        "!wget -O {my_image_2} https://www.dropbox.com/scl/fi/s5089zy9pt5ed10ocn46y/c2.jpg?rlkey=01qndot441zgst8g8cdz0emqw&dl=0\n",
        "!wget -O {my_image_3} https://www.dropbox.com/scl/fi/u65cc3yaz91y45yu28eq8/c3.jpg?rlkey=6ynt5npd51k5z0zqy2k4s17fe&dl=0\n",
        "!wget -O {my_image_4} https://www.dropbox.com/scl/fi/djmfggr7ho1os4nihkzg5/c6.jpeg?rlkey=hdp41x87gac6pvggn7rgf989v&dl=0"
      ],
      "metadata": {
        "id": "U8Ai71yihoeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions and parameters"
      ],
      "metadata": {
        "id": "pY-omJ-pA_MS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xheShAaHpJii"
      },
      "outputs": [],
      "source": [
        "MODEL           = \"gpt-4-vision-preview\"        # selected model for inference\n",
        "# TOP_P           = 1\n",
        "TEMP            = 0.5                           # sampling temperature to use [0...2], with 0.8 already a high value\n",
        "N_RET           = 3                             # how many chat completion choices to generate for each input message\n",
        "MX_TOK          = 1000                          # maximum number of tokens that can be generated in the chat completion\n",
        "DETAIL          = \"high\"                        # with 'low' use 65 tokens to represent the image\n",
        "                                                # with 'high' use 129 tokens\n",
        "                                                # https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding\n",
        "\n",
        "OPENAI_ERRORS   = ( RateLimitError, )           # rate limits are restrictions that OpenAI imposes on the number of times\n",
        "                                                # a user can access our services within a specified period of time\n",
        "                                                # https://platform.openai.com/docs/guides/rate-limits/rate-limits\n",
        "EMERGENCY_DELAY = 4                             # seconds to wait in case of RateLimitError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lByAkY9yusHm"
      },
      "outputs": [],
      "source": [
        "# the model accepts images in base 64 encoded format\n",
        "# https://platform.openai.com/docs/guides/vision/uploading-base-64-encoded-images\n",
        "def encode_b64( img ):\n",
        "  with open( img, \"rb\") as f:\n",
        "    return base64.b64encode( f.read() ).decode( 'utf-8' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_8MttaurtUP"
      },
      "outputs": [],
      "source": [
        "def complete( prmpt, img_b64 ):\n",
        "    # https://platform.openai.com/docs/api-reference/messages/object\n",
        "    message = [ {\n",
        "        'role': 'user',\n",
        "        'content': [\n",
        "            { 'type': 'text',       'text': prmpt  },\n",
        "            { 'type': 'image_url',  'image_url': {\n",
        "                'url':      f\"data:image/jpeg;base64,{img_b64}\",\n",
        "                'detail':   DETAIL\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    } ]\n",
        "\n",
        "    try:\n",
        "        # https://platform.openai.com/docs/api-reference/chat/create\n",
        "        res     = client.chat.completions.create(\n",
        "            model       = MODEL,\n",
        "            messages    = message,\n",
        "            max_tokens  = MX_TOK,\n",
        "            n           = N_RET,\n",
        "            # top_p       = TOP_P,\n",
        "            temperature = TEMP\n",
        "        )\n",
        "\n",
        "    # rate limits are restrictions that OpenAI imposes on the number of times\n",
        "    # a user can access our services within a specified period of time\n",
        "    # https://platform.openai.com/docs/guides/rate-limits/rate-limits\n",
        "    except OPENAI_ERRORS as e:\n",
        "        delay   = EMERGENCY_DELAY\n",
        "        if e is not RateLimitError:\n",
        "            delay   = 5 * delay\n",
        "        print( f\"Catched error: {e}. Now sleeping for {delay} seconds.\" )\n",
        "        time.sleep( delay )\n",
        "\n",
        "        res     = client.chat.completions.create(\n",
        "            model       = MODEL,\n",
        "            messages    = message,\n",
        "            max_tokens  = MX_TOK,\n",
        "            n           = N_RET,\n",
        "            # top_p       = TOP_P,\n",
        "            temperature = TEMP\n",
        "        )\n",
        "\n",
        "    return [ t.message.content for t in res.choices ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize results in a grid using widgets\n",
        "def print_res( prmpt, img, compl ):\n",
        "    grid = widgets.Grid(2, 1)\n",
        "\n",
        "    with grid.output_to( 0, 0 ):\n",
        "        # first row: cell 1 and 2\n",
        "        grid2 = widgets.Grid(1, 2)\n",
        "\n",
        "        # cell 1: input image\n",
        "        with grid2.output_to( 0, 0 ):\n",
        "            i = mpimg.imread( img )\n",
        "            plt.imshow( i )\n",
        "            plt.axis( 'off' )\n",
        "            plt.show()\n",
        "\n",
        "        # cell 2: prompt\n",
        "        with grid2.output_to( 0, 1 ):\n",
        "            print( prmpt )\n",
        "\n",
        "    # second row: cell 3 with one tab for each completion\n",
        "    # cell 3: completions\n",
        "    with grid.output_to( 1, 0 ):\n",
        "        tabbar  = widgets.TabBar( [ f\"COMPL-{i+1}\" for i in range( N_RET ) ] )\n",
        "        for i in range( N_RET ):\n",
        "            with tabbar.output_to( f\"COMPL-{i+1}\" ):\n",
        "                print( compl[ i ] )"
      ],
      "metadata": {
        "id": "rHY5RlaIsSSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute completion\n",
        "def do_exec( prmpt, img ):\n",
        "    img_b64 = encode_b64( img )\n",
        "    compl   = complete( prmpt, img_b64 )\n",
        "    print_res( prmpt, img, compl )\n",
        "    return compl"
      ],
      "metadata": {
        "id": "nptsWbO51Cqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage"
      ],
      "metadata": {
        "id": "G5vizKMaBCbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v0-ukc_qIaR"
      },
      "outputs": [],
      "source": [
        "my_prompt = \"You're the mature driver behind the wheel and this image is what you see now. \"\n",
        "my_prompt += \"Describe what you see and what are the relevant elements. \"\n",
        "my_prompt += \"Then, describe what you plan to do accordingly.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_compl_1 = do_exec( my_prompt, my_image_1 )"
      ],
      "metadata": {
        "id": "IvjfMFMK13Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_compl_2 = do_exec( my_prompt, my_image_2 )"
      ],
      "metadata": {
        "id": "yOkyaov0poFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_compl_3 = do_exec( my_prompt, my_image_3 )"
      ],
      "metadata": {
        "id": "9Oznb38upq2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_compl_4 = do_exec( my_prompt, my_image_4 )"
      ],
      "metadata": {
        "id": "KPnYrHj8-wMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}